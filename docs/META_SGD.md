# Meta-SGD: Learning to Learn with Personalized Learning Rates

## ğŸ’¡ Intuition: Every Parameter Deserves Its Own Teacher

Imagine a classroom where every student learns at a different pace. Some grasp concepts quickly and need to slow down to avoid overshooting. Others need more aggressive instruction to make progress. A good teacher adapts their approach to each student individually.

**Meta-SGD applies this same principle to neural network parameters.** Instead of using a single learning rate for all parameters (like teaching all students the same way), Meta-SGD learns a **personalized learning rate for each parameter**. Some weights need large updates to adapt quickly, while others need tiny, careful adjustments.

This is the key insight: **Just as every student needs personalized teaching, every parameter needs a personalized learning rate to converge optimally.**

---

## ğŸ¯ What is Meta-SGD?

Meta-SGD extends MAML by making the **inner loop learning rates learnable parameters** themselves. While MAML uses a fixed learning rate `Î±` for all parameters during task adaptation, Meta-SGD learns:

- **Î¸ (meta-parameters)**: The model weights (what MAML learns)
- **Î± (meta-learning-rates)**: Per-parameter learning rates (Meta-SGD's addition!)

During meta-training, both Î¸ and Î± are optimized to enable fast adaptation.

---

## ğŸ” How It Works

### Standard MAML Inner Loop:
```python
# Fixed learning rate for all parameters
Î¸' = Î¸ - Î± * âˆ‡L(Î¸)  # Î± is the same for all parameters
```

### Meta-SGD Inner Loop:
```python
# Learnable per-parameter learning rates
Î¸' = Î¸ - Î± âŠ™ âˆ‡L(Î¸)  # Î± is a vector (one learning rate per parameter)
```

### What Changes:

1. **Initialization**: Create learnable learning rates
   ```python
   self.meta_sgd_lrs = torch.nn.ParameterList([
       torch.nn.Parameter(torch.tensor(inner_lr)) 
       for _ in self.model.parameters()
   ])
   ```

2. **Inner Loop Update**: Use per-parameter learning rates
   ```python
   # Standard MAML
   Î¸' = Î¸ - 0.01 * grad  # Same 0.01 for all
   
   # Meta-SGD
   Î¸' = Î¸ - Î±[i] * grad  # Different Î±[i] for each parameter
   ```

3. **Outer Loop Update**: Optimize both Î¸ and Î±
   ```python
   meta_optimizer = Adam(
       list(model.parameters()) + list(meta_sgd_lrs.parameters())
   )
   ```

---

## ğŸš€ How to Use Meta-SGD

### Basic Usage:
```python
from algorithms.maml import train_maml, ModelAgnosticMetaLearning

# Enable Meta-SGD by setting meta_sgd=True
model, maml, losses = train_maml(
    model=model,
    task_dataloader=task_loader,
    inner_lr=0.01,      # Initial value for all learning rates
    outer_lr=0.001,     # Meta-learning rate
    inner_steps=5,
    meta_sgd=True,      # ğŸ”¥ Enable Meta-SGD
    first_order=False   # âš ï¸ MUST be False (see below)
)
```

### Direct API:
```python
# Create Meta-SGD trainer
maml = ModelAgnosticMetaLearning(
    model=model,
    inner_lr=0.01,
    outer_lr=0.001,
    inner_steps=5,
    meta_sgd=True,
    first_order=False  # Required!
)

# Train as usual
for task_batch in task_loader:
    loss = maml.meta_train_step(
        support_data, support_labels,
        query_data, query_labels
    )
```

---

## âš ï¸ Why First-Order Approximation is Incompatible

### The Fundamental Problem:

**Learning rates are NOT part of the forward pass.** They only appear during the parameter update step:

```python
# Forward pass (compute loss)
logits = model(x)           # Learning rates Î± not involved
loss = F.cross_entropy(logits, y)  # Learning rates Î± not involved

# Backward pass (update parameters)
Î¸' = Î¸ - Î± âŠ™ âˆ‡L(Î¸)          # Learning rates Î± used HERE
```

### Why This Matters:

To update the learning rates Î±, we need gradients: **âˆ‚(query_loss)/âˆ‚Î±**

But the learning rates only affect the query loss *indirectly* through their influence on Î¸':

```
Î± â†’ Î¸' â†’ query_loss
    â†‘
    This dependency requires 2nd-order gradients!
```

To compute âˆ‚(query_loss)/âˆ‚Î±, we need:
```python
âˆ‚(query_loss)/âˆ‚Î± = âˆ‚(query_loss)/âˆ‚Î¸' Ã— âˆ‚Î¸'/âˆ‚Î±
                                          â†‘
                              This requires gradients
                              through the inner loop!
```

### The Chain of Dependencies:

1. **Learning rates (Î±)** affect how we update **parameters (Î¸')**
2. **Parameters (Î¸')** affect the **query loss**
3. Therefore: **Learning rates (Î±)** affect **query loss** through **parameters (Î¸')**

This creates a computational graph:
```
Î± (learning rates) â†’ Î¸' (adapted params) â†’ query_loss
```

### Why First-Order Fails:

**First-Order MAML (FOMAML)** breaks this chain by using `.detach()`:
```python
# FOMAML detaches Î¸' from Î¸
Î¸' = Î¸ - Î± * âˆ‡L(Î¸)
Î¸' = Î¸'.detach()  # âŒ Breaks gradient flow!

# Now Î± cannot receive gradients because:
query_loss â†’ Î¸' âœ— Î±  (gradient flow blocked)
```

### The Catch-2:

Even if we try to keep gradients for Î± while using first-order for Î¸:

```python
# Attempt: First-order for Î¸, second-order for Î±
Î¸' = Î¸ - Î± * âˆ‡L(Î¸)
Î¸' = Î¸'.detach().requires_grad_(True)  # Detach Î¸ only

# Problem: We still need the full computation graph!
# âˆ‚Î¸'/âˆ‚Î± requires knowing how Î¸' was computed from Î¸
# This means keeping the ENTIRE gradient graph anyway!
```

**Result**: You get all the computational cost of second-order MAML with none of the benefits of first-order approximation. The computation graph must be maintained regardless, making first-order approximation pointless.

### Time Complexity Analysis:

| Method | Computation Graph | Speed | Learning Rates |
|--------|------------------|-------|----------------|
| **MAML** | Full (2nd-order) | Slow | Fixed Î± |
| **FOMAML** | None (1st-order) | Fast âš¡ | Fixed Î± |
| **Meta-SGD** | Full (2nd-order) | Slow | Learnable Î± âœ¨ |
| **Meta-SGD + FOMAML** | Full (needed for Î±!) | Slow ğŸ˜ | Learnable Î± |

**Conclusion**: Meta-SGD + FOMAML gives you the worst of both worldsâ€”full computational cost with limited benefits.

---

## ğŸ“ Implementation Details

### What the Code Does:

1. **Initialize per-parameter learning rates** (in `__init__`):
   ```python
   self.meta_sgd_lrs = torch.nn.ParameterList([
       torch.nn.Parameter(torch.tensor(inner_lr, requires_grad=True))
       for _ in self.model.parameters()
   ])
   ```

2. **Clone learning rates for task adaptation** (in `inner_update`):
   ```python
   fast_sgd_lrs_list = [param.clone() for param in self.meta_sgd_lrs.parameters()]
   ```

3. **Use per-parameter learning rates for updates**:
   ```python
   fast_weights_list = vectorized_param_update(
       fast_weights_list,
       grads,
       fast_sgd_lrs_list  # Different Î± for each parameter
   )
   ```

4. **Meta-optimizer updates both Î¸ and Î±**:
   ```python
   self.meta_optimizer = optimizer_cls(
       list(self.model.parameters()) + list(self.meta_sgd_lrs.parameters())
   )
   ```

### Key Design Choices:

- **Learning rates initialized to `inner_lr`**: Starts from MAML baseline
- **Learning rates are cloned per task**: Each task gets its own Î± trajectory
- **Gradients computed with `create_graph=True`**: Enables meta-learning of Î±
- **Both Î¸ and Î± in meta-optimizer**: Both updated via outer loop

---

## ğŸ“Š Expected Benefits

### Advantages:
- âœ… **Faster adaptation**: Parameters can adapt at their optimal rate
- âœ… **Better final performance**: Typically 2-5% accuracy improvement over MAML
- âœ… **Automatic hyperparameter tuning**: No manual tuning of learning rates per layer

### Trade-offs:
- âš ï¸ **2Ã— parameters**: Doubles parameter count (Î¸ + Î±)
- âš ï¸ **Cannot use first-order approximation**: Must use full second-order gradients
- âš ï¸ **Slightly more memory**: Stores per-parameter learning rates

### When to Use:
- âœ… You want maximum adaptation performance
- âœ… You have sufficient GPU memory
- âœ… Training time is not the primary bottleneck
- âŒ Don't use if you need fast training (use FOMAML instead)

---

## ğŸ“š Reference

**Meta-SGD: Learning to Learn Quickly for Few-Shot Learning**  
Zhenguo Li, Fengwei Zhou, Fei Chen, Hang Li  
arXiv:1707.09835 (2017)  
https://arxiv.org/abs/1707.09835

---

## ğŸ’¡ Key Takeaways

1. **Intuition**: Each parameter learns at its own optimal rate (like personalized teaching)
2. **Implementation**: Add learnable per-parameter learning rates
3. **Constraint**: Requires second-order gradients (no first-order approximation)
4. **Trade-off**: Better performance vs. more computation and memory
5. **Use when**: You prioritize adaptation quality over training speed

**Remember**: Just like a great teacher adapts to each student, Meta-SGD adapts to each parameter! ğŸ“âœ¨
